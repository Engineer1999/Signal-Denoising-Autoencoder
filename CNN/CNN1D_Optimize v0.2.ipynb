{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN1D Optimize(draft).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelXJames/Signal-Denoising-Autoencoder/blob/master/CNN1D_Optimize%20v0.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ontfmefnFpH9",
        "colab_type": "code",
        "outputId": "a173e6d3-149a-4c9e-d07a-fe7ea82bdb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4195
        }
      },
      "cell_type": "code",
      "source": [
        "#Additional Packages to Install\n",
        "# !pip install pydrive\n",
        "# !pip install git+https://github.com/hyperopt/hyperopt.\n",
        "# !pip install kopt\n",
        "# !pip install oauth2client\n",
        "# !pip install tensorboardcolab\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pydrive\n",
        "from tensorboardcolab import *\n",
        "from random import randint\n",
        "from keras.layers import Dense,Conv1D,Input\n",
        "from keras.layers import MaxPooling1D,UpSampling1D\n",
        "from keras.layers import Activation,BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from kopt import CompileFN, KMongoTrials, test_fn\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "\n",
        "\n",
        "#Authenticate/Create PyDrive client \n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "#Create File in Collab\n",
        "#model_file = drive.CreateFile({'title' : 'backup.json'})\n",
        "#model_file.SetContentFile('model.h5')\n",
        "\n",
        "  \n",
        "#tbc=TensorBoardColab()\n",
        "batch_size = 1000\n",
        "validation_split = 0.15\n",
        "timesteps = 2000\n",
        "features = 1\n",
        "global timesteps\n",
        "global fe#atures\n",
        "\n",
        "\n",
        "#Generate Test/Train Data\n",
        "def create_data(timesteps = 2000):\n",
        "  length = 1\n",
        "  dt = 0.0005\n",
        "  noise_factor = 0.35\n",
        "  data_1 = []\n",
        "  data_noisy_1 = []\n",
        "  for i in range(batch_size):\n",
        "      freq = 30*np.random.random() + 1\n",
        "      t = np.arange(0,length,dt)\n",
        "      #signal = np.arange(-0.5*length,0.5*length,dt)\n",
        "      signal = np.sin(2*np.pi*freq*t)\n",
        "      noisy_signal = signal+noise_factor*np.random.rand(len(t))\n",
        "      data_1.append(signal)\n",
        "      data_noisy_1.append(noisy_signal)\n",
        "  data_1 = np.array(data_1)\n",
        "  data_noisy_1 = np.array(data_noisy_1)\n",
        "  \n",
        "  #Scale Data - Need a better scaler than MinMaxScaler\n",
        "  scaler = MinMaxScaler(feature_range = (0,1))\n",
        "  data_1  = np.vstack((data_1,data_noisy_1))\n",
        "  data_1 = scaler.fit_transform(data_1)\n",
        "  signal = data_1[0:batch_size][:]\n",
        "  signal_noisy = data_1[batch_size:2*batch_size][:]\n",
        "  \n",
        "  #Input Shaping\n",
        "  features = 1\n",
        "  timesteps = len(signal[0])\n",
        "  shape = (batch_size,timesteps,features)\n",
        "  #Input shape should equal [samples, timesteps, features]\n",
        "  x = signal.reshape(shape)\n",
        "  y = signal_noisy.reshape(shape)\n",
        "  \n",
        "  split_point = int((1-validation_split)*batch_size)\n",
        "  \n",
        "  x_train = x[0:split_point,:,:]\n",
        "  y_train = y[0:split_point,:,:]\n",
        "  x_test = x[split_point:batch_size,:,:]\n",
        "  y_test = y[split_point:batch_size][:]\n",
        "\n",
        "  return (x_train,y_train,features),(x_test,y_test)\n",
        "\n",
        "\n",
        "\n",
        "#Gnerate Model For Optimization\n",
        "def create_autoencoder(train_data,max_filters = 32, min_filters = 8, layers = 3,\n",
        "                      kernel_size = 3,filter_spacing = 'lin'):\n",
        "  \n",
        "  timesteps = 2000\n",
        "  features = 1\n",
        "  inputs = Input(shape = (timesteps,features),name = 'Input')\n",
        "  encoded = inputs\n",
        "  \n",
        "  #Linear Filter Range\n",
        "  if filter_spacing == 'lin':\n",
        "    filter_range = np.linspace(max_filters,min_filters,layers,\n",
        "                               dtype = 'int64')\n",
        "  #Half Filter Range\n",
        "  if filter_spacing == 'half':\n",
        "    if max_filters%2 != 0:\n",
        "      max_filters+=1\n",
        "    if min_filters%2 != 0:\n",
        "      min_filters+=1\n",
        "    filter_range = [max_filters]\n",
        "    x = max_filters\n",
        "    while x> min_filters:\n",
        "      x = x/2\n",
        "      filter_range.append(x)\n",
        "    if filter_range[-1] < min_filters:\n",
        "      del filter_range[-1]\n",
        "    filter_range = np.asarray(filter_range,dtype = 'int64')\n",
        "  \n",
        "  #Random Filter Range\n",
        "  if filter_spacing == 'random':\n",
        "    filter_range = [randint(min_filters, max_filters) for z in range(layers)]\n",
        "    filter_range.sort(reverse= True)\n",
        "    filter_range = np.asarray(filter_range)\n",
        "    \n",
        "  conv_name = ''\n",
        "  count = 1\n",
        "  for num_filters in filter_range: \n",
        "    conv_name = 'Conv_Layer_No._{0}'.format(count)\n",
        "    encoded = Conv1D(num_filters,kernel_size,padding = 'same',name = conv_name)(encoded)\n",
        "    count+=1\n",
        "    if(num_filters==max_filters):\n",
        "      encoded = BatchNormalization()(encoded)\n",
        "  \n",
        "    encoded = Activation('relu')(encoded)\n",
        "    encoded = MaxPooling1D(2,padding = 'same')(encoded)\n",
        "  \n",
        "  filter_range = np.sort(filter_range)\n",
        "  for num_filters in filter_range: \n",
        "    conv_name = 'Conv_Layer_No._{0}'.format(count)\n",
        "    encoded = Conv1D(num_filters,kernel_size,padding = 'same',name = conv_name)(encoded)\n",
        "    count+=1\n",
        "    encoded = Activation('relu')(encoded)\n",
        "    encoded = UpSampling1D(2)(encoded)\n",
        "    \n",
        "  decoded = Conv1D(1,kernel_size,activation = 'sigmoid',padding = 'same')(encoded)\n",
        "  \n",
        "  autoencoder = Model(inputs,decoded)\n",
        "  autoencoder.summary()\n",
        "  optimizer = RMSprop(lr=1e-3)\n",
        "  autoencoder.compile(optimizer = optimizer, loss = 'mse')\n",
        "  \n",
        "  return autoencoder\n",
        "\n",
        "\n",
        "#Sample Model - NOT THE OPTIMIZED MODEL\n",
        "def create_Conv1D():\n",
        "  inputs = Input(shape = (timesteps,features))\n",
        "  \n",
        "  encoded = Conv1D(32,3, padding = 'same')(inputs)\n",
        "  encoded = BatchNormalization()(encoded)\n",
        "  encoded = Activation('relu')(encoded)\n",
        "  encoded = MaxPooling1D(2,padding = 'same')(encoded)\n",
        "  \n",
        "  \n",
        "  encoded = Conv1D(16,3,padding = 'same')(encoded)\n",
        "  encoded = Activation('relu')(encoded)\n",
        "  encoded = MaxPooling1D(2,padding = 'same')(encoded)\n",
        "  \n",
        "  encoded = Conv1D(8,3, padding = 'same')(encoded)\n",
        "  encoded = Activation('relu')(encoded)\n",
        "  encoded = MaxPooling1D(2,padding = 'same')(encoded)\n",
        "  \n",
        "  \n",
        "  decoded = Conv1D(8,3,padding = 'same')(encoded)\n",
        "  decoded = Activation('relu')(decoded)\n",
        "  decoded = UpSampling1D(2)(decoded)\n",
        "  \n",
        "  decoded = Conv1D(16,3, padding = 'same')(decoded)\n",
        "  decoded = Activation('relu')(decoded)\n",
        "  decoded = UpSampling1D(2)(decoded)\n",
        "  \n",
        "  decoded = Conv1D(32,3,padding = 'same')(decoded)\n",
        "  decoded = Activation('relu')(decoded)\n",
        "  decoded = UpSampling1D(2)(decoded)\n",
        "  \n",
        "  decoded = Conv1D(1,3,activation = 'sigmoid',padding = 'same')(decoded)\n",
        "  \n",
        "  autoencoder = Model(inputs,decoded)\n",
        "  \n",
        "  optimizer = RMSprop(lr=1e-3)\n",
        "  autoencoder.compile(optimizer = optimizer, loss = 'mse')\n",
        "  autoencoder.summary()\n",
        "  \n",
        "  return autoencoder\n",
        "\n",
        "\n",
        "#HyperParameter Range\n",
        "hyper_params = {\n",
        "    \"data\":{\n",
        "        \n",
        "        \n",
        "    },\n",
        "    \"model\":{\n",
        "        \"max_filters\":hp.choice('mx_filters',np.arange(32,320,dtype = 'int32')),\n",
        "        \"min_filters\":hp.choice('mn_filters',np.arange(4,32,dtype = 'int32')),\n",
        "        'layers':hp.choice('ly',np.arange(3,4,dtype = 'int32')),\n",
        "        'filter_spacing':hp.choice('fs',['lin','half','random'])\n",
        "        \n",
        "    },\n",
        "    \"fit\":{\n",
        "        'epochs': 150,\n",
        "        'patience': 3\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#NN Evaluation\n",
        "db_name = 'sine'\n",
        "exp_name ='exp_1'\n",
        "objective = CompileFN(db_name,exp_name,\n",
        "                      data_fn = create_data,\n",
        "                      model_fn = create_autoencoder,\n",
        "                      loss_metric = 'loss',\n",
        "                      loss_metric_mode = 'min',\n",
        "                      valid_split = None,\n",
        "                      save_model = 'best')\n",
        "#                     save_results = True,\n",
        "#                     save_dir = model_file.SetContentFile('model.h5')\n",
        "                      \n",
        "\n",
        "\n",
        "# model_file.Upload()\n",
        "# drive.CreateFile({'id': model_file.get('id')})\n",
        "\n",
        "#test_fn(objective, hyper_params)\n",
        "trials = Trials()\n",
        "best = fmin(objective, hyper_params, trials=trials, algo=tpe.suggest, max_evals=2)\n",
        "print(trials.trials)\n",
        "#trials = KMongoTrials(db_name, exp_name,\n",
        "#                      ip=\"localhost\",\n",
        "#                      port=22334)\n",
        "#best = fmin(objective, hyper_params, trials=trials, algo=tpe.suggest, max_evals=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "#Save Model to Google Drive\n",
        "# autoencoder.save('model.h5', include_optimizer=False)\n",
        "# model_file = drive.CreateFile({'title' : 'CNN1D_v1.0.h5'})\n",
        "# model_file.SetContentFile('model.h5')\n",
        "# model_file.Upload()\n",
        "# drive.CreateFile({'id': model_file.get('id')})\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-25 06:10:55,483 [INFO] tpe_transform took 0.021171 seconds\n",
            "2018-12-25 06:10:55,485 [INFO] TPE using 0 trials\n",
            "2018-12-25 06:10:55,491 [INFO] Load data...\n",
            "2018-12-25 06:10:56,031 [INFO] Fit...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (None, 2000, 1)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._1 (Conv1D)    (None, 2000, 287)         1148      \n",
            "_________________________________________________________________\n",
            "activation_142 (Activation)  (None, 2000, 287)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_81 (MaxPooling (None, 1000, 287)         0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._2 (Conv1D)    (None, 1000, 285)         245670    \n",
            "_________________________________________________________________\n",
            "activation_143 (Activation)  (None, 1000, 285)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_82 (MaxPooling (None, 500, 285)          0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._3 (Conv1D)    (None, 500, 98)           83888     \n",
            "_________________________________________________________________\n",
            "activation_144 (Activation)  (None, 500, 98)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_83 (MaxPooling (None, 250, 98)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._4 (Conv1D)    (None, 250, 98)           28910     \n",
            "_________________________________________________________________\n",
            "activation_145 (Activation)  (None, 250, 98)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_62 (UpSampling (None, 500, 98)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._5 (Conv1D)    (None, 500, 285)          84075     \n",
            "_________________________________________________________________\n",
            "activation_146 (Activation)  (None, 500, 285)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_63 (UpSampling (None, 1000, 285)         0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._6 (Conv1D)    (None, 1000, 287)         245672    \n",
            "_________________________________________________________________\n",
            "activation_147 (Activation)  (None, 1000, 287)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_64 (UpSampling (None, 2000, 287)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 2000, 1)           862       \n",
            "=================================================================\n",
            "Total params: 690,225\n",
            "Trainable params: 690,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['loss']\n",
            "Train on 850 samples, validate on 150 samples\n",
            "Epoch 1/150\n",
            " - 14s - loss: 0.0449 - val_loss: 0.0085\n",
            "Epoch 2/150\n",
            " - 4s - loss: 0.0093 - val_loss: 0.0100\n",
            "Epoch 3/150\n",
            " - 4s - loss: 0.0089 - val_loss: 0.0070\n",
            "Epoch 4/150\n",
            " - 4s - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 5/150\n",
            " - 4s - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 6/150\n",
            " - 4s - loss: 0.0058 - val_loss: 0.0048\n",
            "Epoch 7/150\n",
            " - 4s - loss: 0.0052 - val_loss: 0.0042\n",
            "Epoch 8/150\n",
            " - 4s - loss: 0.0050 - val_loss: 0.0042\n",
            "Epoch 9/150\n",
            " - 4s - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 10/150\n",
            " - 4s - loss: 0.0044 - val_loss: 0.0043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-25 06:12:13,578 [INFO] Evaluate...\n",
            "2018-12-25 06:12:19,942 [INFO] Done!\n",
            "2018-12-25 06:12:19,973 [INFO] tpe_transform took 0.026975 seconds\n",
            "2018-12-25 06:12:19,974 [INFO] TPE using 1/1 trials with best loss 0.004169\n",
            "2018-12-25 06:12:19,984 [INFO] Load data...\n",
            "2018-12-25 06:12:20,669 [INFO] Fit...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           (None, 2000, 1)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._1 (Conv1D)    (None, 2000, 106)         424       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 2000, 106)         424       \n",
            "_________________________________________________________________\n",
            "activation_148 (Activation)  (None, 2000, 106)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_84 (MaxPooling (None, 1000, 106)         0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._2 (Conv1D)    (None, 1000, 53)          16907     \n",
            "_________________________________________________________________\n",
            "activation_149 (Activation)  (None, 1000, 53)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_85 (MaxPooling (None, 500, 53)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._3 (Conv1D)    (None, 500, 26)           4160      \n",
            "_________________________________________________________________\n",
            "activation_150 (Activation)  (None, 500, 26)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_86 (MaxPooling (None, 250, 26)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._4 (Conv1D)    (None, 250, 26)           2054      \n",
            "_________________________________________________________________\n",
            "activation_151 (Activation)  (None, 250, 26)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_65 (UpSampling (None, 500, 26)           0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._5 (Conv1D)    (None, 500, 53)           4187      \n",
            "_________________________________________________________________\n",
            "activation_152 (Activation)  (None, 500, 53)           0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_66 (UpSampling (None, 1000, 53)          0         \n",
            "_________________________________________________________________\n",
            "Conv_Layer_No._6 (Conv1D)    (None, 1000, 106)         16960     \n",
            "_________________________________________________________________\n",
            "activation_153 (Activation)  (None, 1000, 106)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling1d_67 (UpSampling (None, 2000, 106)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 2000, 1)           319       \n",
            "=================================================================\n",
            "Total params: 45,435\n",
            "Trainable params: 45,223\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n",
            "['loss']\n",
            "Train on 850 samples, validate on 150 samples\n",
            "Epoch 1/150\n",
            " - 12s - loss: 0.0129 - val_loss: 0.0047\n",
            "Epoch 2/150\n",
            " - 2s - loss: 0.0044 - val_loss: 0.0039\n",
            "Epoch 3/150\n",
            " - 2s - loss: 0.0039 - val_loss: 0.0042\n",
            "Epoch 4/150\n",
            " - 2s - loss: 0.0037 - val_loss: 0.0034\n",
            "Epoch 5/150\n",
            " - 2s - loss: 0.0035 - val_loss: 0.0037\n",
            "Epoch 6/150\n",
            " - 2s - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 7/150\n",
            " - 2s - loss: 0.0032 - val_loss: 0.0035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-12-25 06:13:13,870 [INFO] Evaluate...\n",
            "2018-12-25 06:13:20,304 [INFO] Done!\n",
            "2018-12-25 06:13:20,308 [INFO] PROTOCOL mongo\n",
            "2018-12-25 06:13:20,310 [INFO] USERNAME None\n",
            "2018-12-25 06:13:20,312 [INFO] HOSTNAME localhost\n",
            "2018-12-25 06:13:20,313 [INFO] PORT 22334\n",
            "2018-12-25 06:13:20,315 [INFO] PATH /sine/jobs\n",
            "2018-12-25 06:13:20,316 [INFO] AUTH DB None\n",
            "2018-12-25 06:13:20,318 [INFO] DB sine\n",
            "2018-12-25 06:13:20,319 [INFO] COLLECTION jobs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 0.004169232677668333, 'status': 'ok', 'eval': {'loss': 0.004169232677668333}, 'param': {'data': {}, 'fit': {'epochs': 150, 'patience': 3, 'batch_size': 32, 'early_stop_monitor': 'val_loss'}, 'model': {'filter_spacing': 'random', 'layers': 3, 'max_filters': 311, 'min_filters': 10}}, 'path': {'model': '/root/.kopt/data//sine/exp_1//train_models/9a265851-36bd-48b5-b5ac-48801480dc07.h5', 'results': '/root/.kopt/data//sine/exp_1//train_models/9a265851-36bd-48b5-b5ac-48801480dc07.json'}, 'name': {'data': 'create_data', 'model': 'create_autoencoder', 'optim_metric': 'loss', 'optim_metric_mode': 'loss'}, 'history': {'params': {'batch_size': 32, 'epochs': 150, 'steps': None, 'samples': 850, 'verbose': 2, 'do_validation': True, 'metrics': ['loss', 'val_loss']}, 'loss': {'epoch': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'val_loss': [0.008536544901629289, 0.009959137129286925, 0.006997741473217805, 0.007034423239529133, 0.006434278003871441, 0.0048411200319727265, 0.004169230666011572, 0.0042147681551675, 0.004402759851266941, 0.004318775578091542], 'loss': [0.04490372611100183, 0.009277354939018979, 0.008929035963819307, 0.007543062056031297, 0.00653553874724928, 0.0058138314327772925, 0.005180977254229433, 0.004975078613223398, 0.004608106109149316, 0.00435461014180499]}}, 'time': {'start': '2018-12-25 06:10:55.491540', 'end': '2018-12-25 06:12:19.941963', 'duration': {'total': 84.450423, 'dataload': 0.182947, 'training': 84.267476}}}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'fs': [0], 'ly': [0], 'mn_filters': [0], 'mx_filters': [0]}, 'vals': {'fs': [2], 'ly': [0], 'mn_filters': [6], 'mx_filters': [279]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2018, 12, 25, 6, 10, 55, 487000), 'refresh_time': datetime.datetime(2018, 12, 25, 6, 12, 19, 946000)}, {'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 0.003363155061379075, 'status': 'ok', 'eval': {'loss': 0.003363155061379075}, 'param': {'data': {}, 'fit': {'epochs': 150, 'patience': 3, 'batch_size': 32, 'early_stop_monitor': 'val_loss'}, 'model': {'filter_spacing': 'half', 'layers': 3, 'max_filters': 106, 'min_filters': 21}}, 'path': {'model': '/root/.kopt/data//sine/exp_1//train_models/3d5cfb47-7167-43b5-aa68-976536f209c9.h5', 'results': '/root/.kopt/data//sine/exp_1//train_models/3d5cfb47-7167-43b5-aa68-976536f209c9.json'}, 'name': {'data': 'create_data', 'model': 'create_autoencoder', 'optim_metric': 'loss', 'optim_metric_mode': 'loss'}, 'history': {'params': {'batch_size': 32, 'epochs': 150, 'steps': None, 'samples': 850, 'verbose': 2, 'do_validation': True, 'metrics': ['loss', 'val_loss']}, 'loss': {'epoch': [0, 1, 2, 3, 4, 5, 6], 'val_loss': [0.004665151716520389, 0.0038523303469022115, 0.004246339363356431, 0.003363154515003165, 0.003747256152952711, 0.003949108036855857, 0.003464137918005387], 'loss': [0.012881754540345248, 0.004404588513733709, 0.003926665569272111, 0.0037251616422744357, 0.003472748592715053, 0.003280529825235991, 0.0031956429637092]}}, 'time': {'start': '2018-12-25 06:12:19.984649', 'end': '2018-12-25 06:13:20.304465', 'duration': {'total': 60.319816, 'dataload': 0.181343, 'training': 60.138473}}}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'fs': [1], 'ly': [1], 'mn_filters': [1], 'mx_filters': [1]}, 'vals': {'fs': [1], 'ly': [0], 'mn_filters': [17], 'mx_filters': [74]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2018, 12, 25, 6, 12, 19, 977000), 'refresh_time': datetime.datetime(2018, 12, 25, 6, 13, 20, 306000)}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ServerSelectionTimeoutError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e86f8ab55bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m trials = KMongoTrials(db_name, exp_name,\n\u001b[1;32m    281\u001b[0m                       \u001b[0mip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                       port=22334)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;31m#best = fmin(objective, hyper_params, trials=trials, algo=tpe.suggest, max_evals=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kopt/hyopt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, db_name, exp_name, ip, port, kill_timeout, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         super(KMongoTrials, self).__init__(\n\u001b[0;32m--> 117\u001b[0;31m             'mongo://{ip}:{p}/{n}/jobs'.format(ip=ip, p=port, n=db_name), exp_key=exp_name, **kwargs)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/mongoexp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg, exp_key, cmd, workdir, refresh)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mconnection_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoJobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_from_connection_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exp_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/mongoexp.py\u001b[0m in \u001b[0;36mcreate_indexes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_jobs_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_drivers_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/mongoexp.py\u001b[0m in \u001b[0;36mcreate_jobs_indexes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exp_key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result.loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'book_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_drivers_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mcreate_index\u001b[0;34m(self, keys, session, **kwargs)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"maxTimeMS\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0mcmd_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"maxTimeMS\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maxTimeMS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__create_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcmd_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m__create_index\u001b[0;34m(self, keys, index_options, session, **kwargs)\u001b[0m\n\u001b[1;32m   1845\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcollation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_socket_for_writes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     def _command(self, sock_info, command, slave_ok=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_socket_for_writes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_socket_for_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwritable_server_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    222\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    223\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     def select_server_by_address(self, address,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             server_descriptions = self._select_servers_loop(\n\u001b[0;32m--> 183\u001b[0;31m                 selector, server_timeout, address)\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             return [self.get_server_by_address(sd.address)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 199\u001b[0;31m                     self._error_message(selector))\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:22334: [Errno 111] Connection refused"
          ]
        }
      ]
    }
  ]
}
